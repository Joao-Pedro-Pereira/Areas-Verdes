{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ba2a2a-97b0-4d2d-a95d-e2fad56e5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from delta import *\n",
    "from os import PathLike\n",
    "from hdfs import InsecureClient\n",
    "from pyspark.sql.types import LongType, StringType, StructField, StructType, BooleanType, ArrayType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import when, col, concat, lit, substring, avg, sum, count, countDistinct\n",
    "\n",
    "# warehouse_location points to the default location for managed databases and tables\n",
    "warehouse_location = 'hdfs://hdfs-nn:9000/AreasVerdes/warehouse'\n",
    "\n",
    "builder = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"Python Spark DataFrames and SQL\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:1.0.0\") \\\n",
    "    .enableHiveSupport() \\\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a791f5-e3ea-4821-95d0-7f9153961e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "infquintais_gold = spark.table(\"AreasVerdes.infquintais_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bab2e3b-e46a-43e8-836c-b0202bf215ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_compostagem_gold = infquintais_gold \\\n",
    "    .groupBy(\"Borough\",\"Composting\") \\\n",
    "    .agg(\n",
    "        count(infquintais_gold.Composting).alias(\"number_compost\"),\n",
    "    )\n",
    "\n",
    "tipo_compostagem_gold = tipo_compostagem_gold.withColumn(\"number_compost\",col(\"number_compost\").cast(IntegerType())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38a19ab-1c50-4a8b-ada0-a014594cf84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "passeios_filtrados = infquintais_gold.filter((infquintais_gold.TotalSidewalkArea > 0))\n",
    "area_passeios_gold = passeios_filtrados \\\n",
    "    .groupBy(\"Borough\") \\\n",
    "    .agg(\n",
    "        avg(infquintais_gold.TotalSidewalkArea).alias(\"area_sidewalk\"),\n",
    "    )\n",
    "\n",
    "area_passeios_gold = area_passeios_gold.withColumn(\"area_sidewalk\",col(\"area_sidewalk\").cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f18cd51-6a15-405f-9612-e24297b1a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "capturaagua_filtrados = infquintais_gold.filter((infquintais_gold.RainHarvesting == True))\n",
    "media_capturaagua_gold = capturaagua_filtrados \\\n",
    "    .groupBy(\"Borough\") \\\n",
    "    .agg(\n",
    "        avg(infquintais_gold.RainLitres).alias(\"avg_capacity_capturesystem\"),\n",
    "    )\n",
    "media_capturaagua_gold = media_capturaagua_gold.withColumn(\"avg_capacity_capturesystem\",col(\"avg_capacity_capturesystem\").cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68a2f526-3ebc-4914-b100-5a9c731ae280",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_plantas_gold = infquintais_gold \\\n",
    "    .groupBy(\"Borough\",\"Plants\") \\\n",
    "    .agg(\n",
    "        count(infquintais_gold.Plants).alias(\"number_plants\"),\n",
    "    )\n",
    "\n",
    "tipo_plantas_gold = tipo_plantas_gold.withColumn(\"number_plants\",col(\"number_plants\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da897026-bcef-4e2e-86ba-c2c280502daf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tipo_plantas_gold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtipo_plantas_gold\u001b[49m\u001b[38;5;241m.\u001b[39mprintSchema()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tipo_plantas_gold' is not defined"
     ]
    }
   ],
   "source": [
    "tipo_plantas_gold.printSchema();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a91d11-5097-4b2f-a902-d9ac9501820d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "A schema mismatch detected when writing to the Delta table (Table ID: fd07e06d-21bb-4a25-b759-926c87ba5f72).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- Borough: string (nullable = true)\n-- number_onsiteservices: integer (nullable = true)\n\n\nData schema:\nroot\n-- Borough: string (nullable = true)\n-- OnSiteService: boolean (nullable = true)\n-- number_onsiteservices: integer (nullable = true)\n\n         \nTo overwrite your schema or change partitioning, please set:\n'.option(\"overwriteSchema\", \"true\")'.\n\nNote that the schema can't be overwritten when using\n'replaceWhere'.\n         ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#guarda os anos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[43mnumero_fontesagua_gold\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBorough\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOnSiteService\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber_onsiteservices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m----> 7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhdfs://hdfs-nn:9000/AreasVerdes/gold/infquintais/number_onsiteservices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:968\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: A schema mismatch detected when writing to the Delta table (Table ID: fd07e06d-21bb-4a25-b759-926c87ba5f72).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- Borough: string (nullable = true)\n-- number_onsiteservices: integer (nullable = true)\n\n\nData schema:\nroot\n-- Borough: string (nullable = true)\n-- OnSiteService: boolean (nullable = true)\n-- number_onsiteservices: integer (nullable = true)\n\n         \nTo overwrite your schema or change partitioning, please set:\n'.option(\"overwriteSchema\", \"true\")'.\n\nNote that the schema can't be overwritten when using\n'replaceWhere'.\n         "
     ]
    }
   ],
   "source": [
    "#guarda os anos\n",
    "numero_fontesagua_gold \\\n",
    "    .select(\"Borough\",\"OnSiteService\",\"number_onsiteservices\") \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .save(\"hdfs://hdfs-nn:9000/AreasVerdes/gold/infquintais/number_onsiteservices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ecfe874-0f6d-4068-aec6-a2928d356855",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_plantas_gold \\\n",
    "    .select(\"Borough\",\"Plants\",\"number_plants\") \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .save(\"hdfs://hdfs-nn:9000/AreasVerdes/gold/infquintais/numero_plantas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23649e1e-566c-45da-b0ce-94a0db7d5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_compostagem_gold \\\n",
    "    .select(\"Borough\",\"Composting\",\"number_compost\") \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .save(\"hdfs://hdfs-nn:9000/AreasVerdes/gold/infquintais/numero_compostagem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d403503-bedc-4c18-b076-be24c367febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_passeios_gold \\\n",
    "    .select(\"Borough\",\"area_sidewalk\") \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .save(\"hdfs://hdfs-nn:9000/AreasVerdes/gold/infquintais/area_sidewalk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a541de67-e2ee-459d-a54c-807f602f2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_capturaagua_gold \\\n",
    "    .select(\"Borough\",\"avg_capacity_capturesystem\") \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .save(\"hdfs://hdfs-nn:9000/AreasVerdes/gold/infquintais/avg_capacity_capturesystem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3292ae99-3465-413b-a78c-14d4be2b310f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39msql(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    SELECT *\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    FROM AreasVerdes.avg_capacity_capturesystem\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM AreasVerdes.avg_capacity_capturesystem\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab64458-0d68-49e3-b2f7-70473a3264da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
